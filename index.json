[{"categories":["Python"],"content":"一句话定义 装饰器本质上是一个Python函数或类，它可以让其他函数或类在不需要做任何代码修改的前提下增加额外功能，装饰器的返回值也是一个函数/类对象。 在闭包的笔记中提到装饰器的形式：decorated = outer(foo)，类似“套娃”。 ","date":"2023-07-01","objectID":"/posts/decorator/:1:0","tags":["Python"],"title":"装饰器","uri":"/posts/decorator/"},{"categories":["Python"],"content":"函数装饰器 def decorator(fn): def wrapper(arg): print(\"In wrapper, arg is %s, fn is %s\"%(arg, fn.__name__)) return fn(arg) return wrapper @decorator def outer(arg): print(\"In outer, arg is %s\"%arg) print(\"Finished decorating outer()\") print(outer) outer(\"walle\") #output Finished decorating outer() \u003cfunction decorator.\u003clocals\u003e.wrapper at 0x7f897871e3b0\u003e In wrapper, arg is walle, fn is outer In outer, arg is walle 由print(outer)的输出是wrapper函数可以看出，decorator 这个函数套在outer外面，即原来的outer函数被装饰了，以上的封装过程是： outer = decorator(outer) # 这里的装饰器返回的是一个函数 outer(\"walle\")等价于decorator(outer)(\"waller\")等价于wrapper(\"waller\")。 所以walle in wrapper, fn is outer是wrapper的print()输出的。walle in outer是在wrapper的fn(arg)输出的。 由此可以看出，装饰器的价值就是在wrapper的函数中搞事情，而且还可以继续调用被装饰的函数。 ","date":"2023-07-01","objectID":"/posts/decorator/:2:0","tags":["Python"],"title":"装饰器","uri":"/posts/decorator/"},{"categories":["Python"],"content":"类装饰器 class Decorator(object): def __init__(self, fn): print(\"In __init__, fn is %s\"%fn.__name__) self.fn = fn def __call__(self, arg): print(\"In __call__, arg %s\"%arg) self.fn(arg) @Decorator def outer(arg): print(\"In outer, arg %s\"%arg) print(\"Finished decorating outer()\") print(outer) outer(\"walle\") #output In __init__, fn is outer Finished decorating outer() \u003c__main__.Decorator object at 0x7f6d773d31f0\u003e In __call__, arg is walle In outer, arg is walle 由此执行结果可见，装饰过程只调用了该类的__init__函数，被装饰后实际返回的是一个Decorator的一个实例，以上的封装过程是： outer = Decorator(outer) # 这里的装饰器返回的是一个类的实例对象 因为装饰的过程是类的实例化过程，所以称之为类装饰。 __call__()是一个非常特殊的实例方法。该方法的功能类似于在类中重载()运算符，使得类实例对象可以像调用普通函数那样，以“对象名()”的形式使用。 所以outer(\"walle\")就等价于Decorator(outer)(\"walle\")，Decorator(outer)是一个实例化对象（这里我们用outer_obj表示），所以最后就是outer_obj('walle')，这就调用到了__call__()的逻辑。 ","date":"2023-07-01","objectID":"/posts/decorator/:3:0","tags":["Python"],"title":"装饰器","uri":"/posts/decorator/"},{"categories":["Python"],"content":"对象装饰器 class Decorator(object): def __init__(self, arg): print(\"In __init__, arg is %s\"%arg) self.arg = arg def __call__(self, fn): print(\"In __call__, fn is %s\"%fn.__name__) def wrapper(arg): arg = self.arg + ' ' +arg fn(arg) return wrapper @Decorator(\"Hello\") def outer(arg1): print(\"%sIn outer\"%arg1) print(\"Finished decorating outer()\") print(outer) outer(\"walle\") #output In __init__, arg is Hello In __call__, fn is outer Finished decorating outer() \u003cfunction Decorator.__call__.\u003clocals\u003e.wrapper at 0x7f468ba19c60\u003e Hello walle In outer 由此执行结果可见，装饰过程只调用了该类的__init__函数和实例函数__call__，装饰后的结果就是执行了__call__的结果，即返回了一个函数，以上的封装过程是： outer = Decorator('hello')(outer) # 这里的装饰器返回的是一个函数 因为装饰的过程是类实例化的对象被调用的过程，所以称之为对象装饰器。 所以outer(\"walle\")就等价于Decorator(\"Hello\")(outer)(\"walle\")，Decorator(\"Hello\")是一个实例化对象，Decorator(\"Hello\")(outer)是实例化对象调用了__call__()，该过程返回了wrapper函数。 ","date":"2023-07-01","objectID":"/posts/decorator/:4:0","tags":["Python"],"title":"装饰器","uri":"/posts/decorator/"},{"categories":["Python"],"content":"装饰器顺序 def decorator_a(func): print('In decorator_a') def inner_a(*args, **kwargs): print('In inner_a') func(*args, **kwargs) print('In inner_a, post') return inner_a def decorator_b(func): print('In decorator_b') def inner_b(*args, **kwargs): print('In inner_b') func(*args, **kwargs) print('In inner_b, post') return inner_b @decorator_b @decorator_a def outer(arg): print(\"In outer, arg is %s\"%arg) print(\"Finished decorating outer()\") print(outer) outer(\"walle\") #output In decorator_a In decorator_b Finished decorating outer() \u003cfunction decorator_b.\u003clocals\u003e.inner_b at 0x7f6b711d6170\u003e In inner_b In inner_a In outer, arg is walle In inner_a, post In inner_b, pos 由执行结果中先执行了decorator_a的逻辑，再执行decorator_b的逻辑，最终返回的是inner_b，可见以上的封装过程为： outer = decorator_b(decorator_a(outer)) # 这里的装饰器返回的是一个函数 decorator_a(outer)的执行结果是返回了inner_a，decorator_b(inner_a)的执行结果是返回一个inner_b。 当outer(\"walle\")传入参数进行调用时，就是调用inner_b(\"walle\")，它会先打印In inner_b，然后在inner_b内部调用了fun即inner_a，所以会再打印In inner_a, 然后再inner_a内部调用的原来的fun即outer。 ","date":"2023-07-01","objectID":"/posts/decorator/:5:0","tags":["Python"],"title":"装饰器","uri":"/posts/decorator/"},{"categories":["Docker"],"content":"编排依赖的服务容器 这里，容器化准备开发所依赖的环境。 下面的示例配置了redis，minio，postgres_db, registry的服务。其他的开发环境也可以按需添加。 ---version:'3'services:redis:image:redis:6.2.7-alpine3.16ports:- \"127.0.0.1:26379:6379\"minio:image:minio/minio:RELEASE.2023-02-27T18-10-45Zcommand:- server- /srv/minioports:- \"29000:9000\"volumes:- minio-data:/srv/minio:rwenvironment:MINIO_ACCESS_KEY:\"access\"MINIO_SECRET_KEY:\"secret-key\"db:image:postgres:12.11-alpine3.16ports:- \"25432:5432\"volumes:- db-data:/var/lib/postgresql/dataenvironment:POSTGRES_USER:postgresPOSTGRES_DB:hjw-devPOSTGRES_PASSWORD:passwordregistry:image:registry:2.8.1ports:- \"25000:5000\"environment:REGISTRY_STORAGE:s3REGISTRY_STORAGE_S3_ACCESSKEY:accessREGISTRY_STORAGE_S3_SECRETKEY:secret-keyREGISTRY_STORAGE_S3_REGION:localREGISTRY_STORAGE_S3_BUCKET:registryREGISTRY_STORAGE_S3_REGIONENDPOINT:http://localhost:29000volumes:minio-data:db-data: ","date":"2023-07-01","objectID":"/posts/dev-env/:1:0","tags":["Docker"],"title":"开发环境准备","uri":"/posts/dev-env/"},{"categories":["Docker"],"content":"docker-compose 开机自启动 为了方便，以上的服务可以配置在开机的时候就绪。 新建并编辑/etc/systemd/system/docker-compose-dev-app.service [Unit] Description=Docker Compose Develop Application Service Requires=docker.service After=docker.service [Service] Type=oneshot RemainAfterExit=yes WorkingDirectory=/home/hjw/Code/python-example/dev ExecStart=/usr/bin/docker-compose up -d ExecStop=/usr/bin/docker-compose down TimeoutStartSec=0 [Install] WantedBy=multi-user.target 以上的WorkingDirectory需要配置真实的docker-compose文件的所在目录，需填写绝对路径。 然后执行： sudo systemctl enable docker-compose-dev-app.service 如果失败可以用以下命令查看详细原因。 sudo systemctl status docker-compose-dev-app.service ","date":"2023-07-01","objectID":"/posts/dev-env/:2:0","tags":["Docker"],"title":"开发环境准备","uri":"/posts/dev-env/"},{"categories":["Python"],"content":"闭包 ","date":"2023-05-21","objectID":"/posts/closure/:1:0","tags":["Python"],"title":"闭包","uri":"/posts/closure/"},{"categories":["Python"],"content":"定义 闭包，是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。 有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。 闭包在实现上是一个结构体，它存储了一个函数（通常是其入口地址）和一个关联的环境（相当于一个符号查找表）。 环境里是若干对符号和值的对应关系，它既要包括约束变量（该函数内部绑定的符号）， 也要包括自由变量（在函数外部定义但在函数内被引用），有些函数也可能没有自由变量。 闭包跟函数最大的不同在于，当捕捉闭包的时候，它的自由变量会在捕捉时被确定，这样即便脱离了捕捉时的上下文，它也能照常运行。 自由变量：没有在作用域中被定义的变量？ ","date":"2023-05-21","objectID":"/posts/closure/:1:1","tags":["Python"],"title":"闭包","uri":"/posts/closure/"},{"categories":["Python"],"content":"变量作用域 从一个例子分析： \u003e\u003e\u003e b = 1 \u003e\u003e\u003e def outer(a): print(a) print(b) b = 3 \u003e\u003e\u003e outer(2) 2 Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e File \"\u003cstdin\u003e\", line 3, in outer UnboundLocalError: local variable 'b' referenced before assignment 变量搜索，当在函数中访问一个新的变量是，Python会在当前的命名空间中寻找变量是否存在。如果变量不存在则会从上一级命名空间中搜索，直到顶层命名空间。 调用outer()函数时，会正常打印出参数变量a。执行到变量b的时候，会在当前的函数作用域中查询，但是在执行打印变量的时候，检测到赋值语句在其之后，所以报错。以上函数想要正常运行的话，可以去掉函数中的赋值语句，由于所在函数内没有变量则会向上一级搜寻，则会打印出b=1的结果。或者也可以用在函数内用global b来将其申明为全局变量。 ","date":"2023-05-21","objectID":"/posts/closure/:1:2","tags":["Python"],"title":"闭包","uri":"/posts/closure/"},{"categories":["Python"],"content":"闭包函数 函数对象的__closure__属性指示了该函数对象是否是闭包函数，若不是闭包函数，则该属性值为None，否则为一个非空元组。 创建一个计算系列值的均值的逻辑。 class Averager(): def __init__(self): self.series = [] def __call__(self, new_value): self.series.append(new_value) total = sum(self.series) return totle / len(self.series) avg = Averager() avg(10) # 10.0 avg(11) # 10.5 avg(12) # 11.0 以上逻辑是通过类实现，self.series是实例变量。不属于自由变量，因为在类的作用域中已被定义。 def make_averager(): #-----闭包----- series = [] def averager(new_value): # series是自由变量 series.append(new_value) total = sum(series) return totle / len(series) #-------------- return averager avg = make_averager() avg(10) # 10.0 avg(11) # 10.5 avg(12) # 11.0 avg.__closure__ # (\u003ccell at 0x7f3f4f4ecee0: list object at 0x7f3f4f634b80\u003e,) 以上逻辑是通过函数实现，make_averager()在局部作用域中定义了series变量，它的内部函数averager()的自由变量series绑定了这个值，这就组成了所谓的闭包。如果没有闭包特性的话，自由变量series一定会报错找不到定义，因为在调用avg(10)时，make_averager()函数已经返回了，它的局部作用域也消失了。闭包是一种函数，它会保留定义时存在的自由变量的绑定，这样调用函数时，虽然定义作用域不可用了，但是仍然能使用那些绑定。 ","date":"2023-05-21","objectID":"/posts/closure/:1:3","tags":["Python"],"title":"闭包","uri":"/posts/closure/"},{"categories":["Python"],"content":"nonlocal def make_averager(): count = 0 total = 0 def averager(new_value): count += 1 total += new_value return total / count return averager avg = make_averager() avg(10) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e File \"\u003cstdin\u003e\", line 6, in averager UnboundLocalError: local variable 'count' referenced before assignment 以上报错是因为count +=1等同于count = count + 1，存在赋值，count就变成局部变量了。当然，total变量也是如此。 这里如果把count和total通过global关键字声明为全局变量，显然是不合适的，它们作用域最多只扩展到make_averager()函数内。为了解决这个问题，Python3引入了nonlocal关键字声明： def make_averager(): count = 0 total = 0 def averager(new_value): nonlocal count, total count += 1 total += new_value return total / count return averager nonlocal的作用是把变量标记为自由变量，即使在函数中为变量赋值了，也仍然是自由变量。 注意，对于列表、字典等可变类型来说，添加元素不是赋值，不会隐式创建局部变量。对于数字、字符串、元组等不可变类型以及None来说，赋值会隐式创建局部变量。示例： def make_averager(): # 可变类型 count = {} def averager(new_value): print(count) # 成功 count[new_value] = new_value return count return averager ","date":"2023-05-21","objectID":"/posts/closure/:1:4","tags":["Python"],"title":"闭包","uri":"/posts/closure/"},{"categories":["Python"],"content":"闭包和装饰器 def outer(x): def inner(y): print(x + y) return inner 以上的闭包函数的自由变量x是外层函数的参数变量。 我们可以利用闭包的特性得到一个对已有函数运行行为进行扩充或修改的新函数，而同时保留已有函数，不用对已有函数的代码进行修改。 做到这个的第一步是将函数作为参数传递到我们的“闭包创建函数”（例子中的outer）中，如decorated = outer(foo)，decorated是foo的装饰版，即给foo加上了一些东西，调用decorated()就是调用装饰器了。 ","date":"2023-05-21","objectID":"/posts/closure/:1:5","tags":["Python"],"title":"闭包","uri":"/posts/closure/"},{"categories":["Command"],"content":"ssh公钥免密登录 ssh-copy-id -i ~/.ssh/id_rsa.pub 用户名@ip地址 以上命令会将本地的ssh公钥拷贝到目标机器的.ssh目录下，文件名为authorized_keys。 当然如果不知道目标机器密码的话，需要将公钥委托给目标机器的管理员进行添加。 ","date":"2023-05-21","objectID":"/posts/command/:1:0","tags":["Command"],"title":"命令备忘录","uri":"/posts/command/"},{"categories":["Command"],"content":"openssl获取服务端证书 openssl s_client -connect www.github.com:443 ","date":"2023-05-21","objectID":"/posts/command/:2:0","tags":["Command"],"title":"命令备忘录","uri":"/posts/command/"},{"categories":["Docker","Kubernetes"],"content":"Entrypoint和CMD No ENTRYPOINT ENTRYPOINT exec_entry p1_entry ENTRYPOINT [“exec_entry”, “p1_entry”] No CMD error, not allowed /bin/sh -c exec_entry p1_entry exec_entry p1_entry CMD [“exec_cmd”, “p1_cmd”] exec_cmd p1_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry exec_cmd p1_cmd CMD [“p1_cmd”, “p2_cmd”] p1_cmd p2_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry p1_cmd p2_cmd CMD exec_cmd p1_cmd /bin/sh -c exec_cmd p1_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd ","date":"2022-10-08","objectID":"/posts/cmd/:0:1","tags":["Docker","Kubernetes"],"title":"镜像和容器的Entrypoint和CMD","uri":"/posts/cmd/"},{"categories":["Docker","Kubernetes"],"content":"镜像和容器 镜像 Entrypint 镜像 Cmd 容器 command 容器 args 执行命令 [/ep-1] [foo bar] [ep-1 foo bar] [/ep-1] [foo bar] [/ep-2] [ep-2] [/ep-1] [foo bar] [zoo boo ] [ep-1 zoo boo] [/ep-1] [foo bar] [/ep-2] [zoo boo ] [ep-2 zoo boo] ","date":"2022-10-08","objectID":"/posts/cmd/:0:2","tags":["Docker","Kubernetes"],"title":"镜像和容器的Entrypoint和CMD","uri":"/posts/cmd/"},{"categories":["“Docker”","Registry"],"content":"认证方案 Registry的授权方案是基于OAuth2.0的密码模式。 上面代表的是以Docker举例的Registry的认证鉴权方案： 1.Docker Daemon尝试向Registry发起请求。 2.如果Regsitry要求认证的话，会返回401 Unauthorized并带有认证服务的信息。 3.Docker Daemon向Authrization Service请求token。 4.Authrization Service返回客户端认证后的权限。 5.Docker Daemon将token放在header的Authorization的字段中再次向Registry发起请求。 6.Regestry解析token，并根据token中包含的权限信息开始push或者pull的会话连接。 ","date":"2022-09-04","objectID":"/posts/auth/:1:0","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"请求token 本小节的内容是关于上图中的步骤3的详解。 在请求Token的API中，有以下参数： ","date":"2022-09-04","objectID":"/posts/auth/:2:0","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"Query Parameters service：（neccessary）授权服务的标识，表示要向谁请求token scope：（neccessary） client-id：（optinal）请求token的客户端id，比如docker-daemon发起的请求会将该字段设置为docker。 ","date":"2022-09-04","objectID":"/posts/auth/:2:1","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"Header Parameters uthorization：（optional）携带的用户信息 ","date":"2022-09-04","objectID":"/posts/auth/:2:2","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"Response Body 响应body为一个json，有三个字段: token：（neccessary）授权服务器返回的带有授权信息的token。 issued_at：（optional）token的签发时间，UTC标准时间格式。 expires_in：（optional）token在多少秒以后过期，如果没有说明则默认为60秒。 ","date":"2022-09-04","objectID":"/posts/auth/:2:3","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"示例 $ curl 192.168.1.103:8021/service/token?service=token-service\\\u0026scope=repository:library/registry:pull\\\u0026client_id=curl { \"expires_in\": 1800, \"issued_at\": \"2018-09-05T08:34:40Z\", \"token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IkhNNjY6NkNYUzpaQlBROk1ENVo6QlJZVTpTVE9EOkNCUEs6Uk5ORjpYN0VDOkZMUUw6TFNFMjpLUUtTIn0.eyJpc3MiOiJyZWdpc3RyeS10b2tlbi1pc3N1ZXIiLCJzdWIiOiIiLCJhdWQiOiJ0b2tlbi1zZXJ2aWNlIiwiZXhwIjoxNTM2MTM4MjgwLCJuYmYiOjE1MzYxMzY0ODAsImlhdCI6MTUzNjEzNjQ4MCwianRpIjoiZFpxVkgxVDFjZkhXdnFZTiIsImFjY2VzcyI6W3sidHlwZSI6InJlcG9zaXRvcnkiLCJuYW1lIjoibGlicmFyeS9yZWdpc3RyeSIsImFjdGlvbnMiOlsicHVsbCJdfV19.ilCKa2-oJ9bKQpAo8ntcx1lHpbs0BcWYtbRrvItHAProaDEDpll9EZrzkzg6XR9OOLByFm_oJKKk8Y_wYwQfxYdjvhLbFjCNXzE6MckY8dEcSR5BmYxOK54zAqNVkw24ugUcagGFi7p8Gy0YZqBqf7AP8qCarhuWhKsZ7B4esMQk2xBEn1hh8r_9tb6wnZOkDl7trW0IWbPkqKSaP8ycq8oS9J0T6zaItyTLnERsV_GFJOh6DdfhSYzGwoWUFQH6cmp05ZHXF_-4O6N6d8tosGH9gTsam-ffeVHmWp8da_gpS_R15z3ELR5I2FO0s4gWo1UbTI3yuyV8stSURrCs6GHZSMb2C9_2R2r_Q-uDKmdpoazw2G1DxM3PgfXEwANWEjPJMjD0areUXmjwz_hefSMqYFxLi26TaQinG0th7pNz5m0qroefOy1AGyhRZK-t8rsduZJ9EWQCqtXHrPbTES0FoItJmcMqcJZcvQsrJsBMirtijvGdNn55l44-eDFyrIuExerHzU1dJoSijCtqIYxbdnclLE8HSP-vnBD5TOAJoUUdUfA1N8TvF2QqDjr_LATUOctahrFoWiuDjrFXH-ptmcJJ6lPjo1oCOne3ImKe_mieRR7YCOQLejuCbItIIweuqwBzJU5d33k3Drra0qvbvk-MkO7iBNgpCtfWqD8\" } 我们可以把上面的token拷贝到网页jwt.io中，查看token的明文形式。 在上面获取token的请求中，没有携带任何的用户信息。不过我们可以使用添加用户信息（用户名与密码）去获取token，如下： $ curl -H \"Authorization: Basic YWRtaW46SGFyYm9yMTIzNDU=\" 192.168.1.103:8021/service/token?service=token-service\\\u0026scope=repository:library/registry:pull\\\u0026client_id=curl 其中YWRtaW46SGFyYm9yMTIzNDU=是admin:Harbor12345的base64编码 ","date":"2022-09-04","objectID":"/posts/auth/:2:4","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"生成token 本小节主要是分析Authrization Service生成JWT的过程。 token由三部分内容组成：Header、Payload和Signature。token的形式如下： {token-header}.{token-payload}.{token-signature} ","date":"2022-09-04","objectID":"/posts/auth/:3:0","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"Header Header有三个字段： typ：固定为JWT alg：签名算法，常用的有HS256、RS256等 kid：key-id，签名算法中所使用的密钥的ID值 kid的生成有以下三个步骤: 1、从签名算法使用的密钥中得到DER编码格式的公钥（public key 2、对DER格式的公钥做sha256哈希，取前240bit 3、将这240bit使用base32编码，然后四个一组使用冒号:分隔 如下是Header的一个例子: { \"typ\": \"JWT\", \"alg\": \"RS256\", \"kid\"：\"HM66:6CXS:ZBPQ:MD5Z:BRYU:STOD:CBPK:RNNF:X7EC:FLQL:LSE2:KQKS\" } 生成kid的详细例子见本文末尾的扩展阅读。 ","date":"2022-09-04","objectID":"/posts/auth/:3:1","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"Payload payload中的字段有： iss：（Issuer），token的签发者 sub：（Subject），正在进行认证的用户的名字，如果是匿名用户则为空 aud：（Audience），token的观众，即需要对token进行验证的服务的名字 exp：（Expiration），过期时间，在这之后token应该看作是无效的；时间戳格式 nbf：（Not Before），token有效的超始时间，在这之前token应当看作是无效的；时间戳格式 iat：（Issued At），签发时间；时间戳格式 jti：（JWT ID），token的id，（尚不清楚如何生成） access：权限集，下面还有三个字段 type name actions payload的样例如下： { \"iss\": \"registry-token-issuer\", \"sub\": \"\", \"aud\": \"token-service\", \"exp\": 1536204479, \"nbf\": 1536202679, \"iat\": 1536202679, \"jti\": \"KF76FTQQ4tIvvCbR\", \"access\": [ { \"type\": \"repository\", \"name\": \"library/registry\", \"actions\": [ \"pull\" ] } ] } ","date":"2022-09-04","objectID":"/posts/auth/:3:2","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"Signature Header处理 对header内容去掉空白字符后得到： { \"typ\":\"JWT\", \"alg\":\"RS256\", \"kid\":\"HM66:6CXS:ZBPQ:MD5Z:BRYU:STOD:CBPK:RNNF:X7EC:FLQL:LSE2:KQKS\" } 然后对该字符串进行base64Url编码（base64在线编码网址），得到token-header，base64Url就是先进行base64编码，再把得到的字符串中的+变成-，/变成_，去掉=。 eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IkhNNjY6NkNYUzpaQlBROk1ENVo6QlJZVTpTVE9EOkNCUEs6Uk5ORjpYN0VDOkZMUUw6TFNFMjpLUUtTIn0 Payload处理 payload内容去掉空白字符后得到： { \"iss\":\"registry-token-issuer\", \"sub\":\"\",\"aud\":\"token-service\", \"exp\":1536204479, \"nbf\":1536202679, \"iat\":1536202679, \"jti\":\"KF76FTQQ4tIvvCbR\", \"access\": [ { \"type\":\"repository\", name\":\"library/registry\", \"actions\":[\"pull\"], } ] } 然后对该字符串进行base64Url编码，得到token-payload： eyJpc3MiOiJyZWdpc3RyeS10b2tlbi1pc3N1ZXIiLCJzdWIiOiIiLCJhdWQiOiJ0b2tlbi1zZXJ2aWNlIiwiZXhwIjoxNTM2MjA0NDc5LCJuYmYiOjE1MzYyMDI2NzksImlhdCI6MTUzNjIwMjY3OSwianRpIjoiS0Y3NkZUUVE0dEl2dkNiUiIsImFjY2VzcyI6W3sidHlwZSI6InJlcG9zaXRvcnkiLCJuYW1lIjoibGlicmFyeS9yZWdpc3RyeSIsImFjdGlvbnMiOlsicHVsbCJdfV19 signature处理 token-signature的计算方法如下，先对token-header + “.” + token-payload做sha256哈希（RS256就是RSA+SHA256），然后再使用RSA的私钥进行签名（sign），最后用base64Url进行编码，得到signature-token： token-signature = base64Url(sign(sha256(token-header+\".\"+token-payload))) 由前面的token-header与token-payload得到的token-signature如下（RSA密钥见扩展阅读）: e91bTpXSYNUTcUXr7zs62ZgCm1L6bhZbbW4ujXFY9Zzdkvy3DEHDssq6R4K9f5ESvv_LrWxxIxIXVREAATw-FaykcAewyjarC6Vlj2g0ea6D9L1HsIvsqtYcBOnHIJ5CRPJPhXWPwBtbujgNgbti-LLeVprOwaJ8fDk21UikmYFhX61_IobFukWw1ByXiNt8byU6tOrxkkDp-YXpz9y-XP5FdheGwNxOREph40znA9LddUcEuQUHB5WKQ3tdU4sqXOW3TUCtjLOl-kVREcus-83fLSuob1lZWRbzU9dEROd_5ZP4NNmD4ZY0DhcYbp75UqvB-MZIiC9MDeOheHAsPGB4Kqu2gBshRd_NJIrQkig7yvD2Wo7twn1KKSznHp6lcsK5phkkkWMVbZoD3qV76MqCDKVSkD2JOgQ0l4AhcYEGLtxx_ukk4NlDCYoljnGPw1oEynmFDROSvMg_bqhRVUF-5US83sU0l6YWwRCZT6StTvdSHp79wbSXgEn58-NO64AtVuMEb1XiDhDxtgaF0K61UwjBRmhpcCurw0laknBVVlta6otbfQcbyQn6ulsKgbrBKka-vkgo4_ymCyqnSXuZYC2Oz_PYawgGVz3s4JXhedoVWiUSDbyKYnFTXdtTign5oT6H6N-K1YKLoGSxma3uUwdDZP2hKH_UH_V9eOY 最后，对token-header、token-payload和token-signature进行组装，得到最终的token: eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IkhNNjY6NkNYUzpaQlBROk1ENVo6QlJZVTpTVE9EOkNCUEs6Uk5ORjpYN0VDOkZMUUw6TFNFMjpLUUtTIn0.eyJpc3MiOiJyZWdpc3RyeS10b2tlbi1pc3N1ZXIiLCJzdWIiOiIiLCJhdWQiOiJ0b2tlbi1zZXJ2aWNlIiwiZXhwIjoxNTM2NTY4NDcxLCJuYmYiOjE1MzY1NjY2NzEsImlhdCI6MTUzNjU2NjY3MSwianRpIjoiaU1kYm5td2dLQ2dUTk4xdyIsImFjY2VzcyI6W3sidHlwZSI6InJlcG9zaXRvcnkiLCJuYW1lIjoibGlicmFyeS9yZWdpc3RyeSIsImFjdGlvbnMiOlsicHVsbCJdfV19.e91bTpXSYNUTcUXr7zs62ZgCm1L6bhZbbW4ujXFY9Zzdkvy3DEHDssq6R4K9f5ESvv_LrWxxIxIXVREAATw-FaykcAewyjarC6Vlj2g0ea6D9L1HsIvsqtYcBOnHIJ5CRPJPhXWPwBtbujgNgbti-LLeVprOwaJ8fDk21UikmYFhX61_IobFukWw1ByXiNt8byU6tOrxkkDp-YXpz9y-XP5FdheGwNxOREph40znA9LddUcEuQUHB5WKQ3tdU4sqXOW3TUCtjLOl-kVREcus-83fLSuob1lZWRbzU9dEROd_5ZP4NNmD4ZY0DhcYbp75UqvB-MZIiC9MDeOheHAsPGB4Kqu2gBshRd_NJIrQkig7yvD2Wo7twn1KKSznHp6lcsK5phkkkWMVbZoD3qV76MqCDKVSkD2JOgQ0l4AhcYEGLtxx_ukk4NlDCYoljnGPw1oEynmFDROSvMg_bqhRVUF-5US83sU0l6YWwRCZT6StTvdSHp79wbSXgEn58-NO64AtVuMEb1XiDhDxtgaF0K61UwjBRmhpcCurw0laknBVVlta6otbfQcbyQn6ulsKgbrBKka-vkgo4_ymCyqnSXuZYC2Oz_PYawgGVz3s4JXhedoVWiUSDbyKYnFTXdtTign5oT6H6N-K1YKLoGSxma3uUwdDZP2hKH_UH_V9eOY ","date":"2022-09-04","objectID":"/posts/auth/:3:3","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"使用Token 在得到token后，我们就可以在API请求的Header中添加token信息，比如下载镜像的manifest： curl -H \"Authorization: Bearer [token]\" 192.168.1.103:8021/v2/library/registry/manifests/2.5.0 ","date":"2022-09-04","objectID":"/posts/auth/:4:0","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"验证Token 当Registry接收到一个携带token的API请求时，Registry需要从以下几个方面来验证Token: token的签发者（payload中的iss）是可信的，即和registry的配置参数issuer一致 确保registry是该token的观众，即payload中的aud与registry的配置参数token-service一致 检查payload中的nbf与exp确保token在有效期内 检查payload的access字段，确保该token能够访问该API 检查token的签名 ","date":"2022-09-04","objectID":"/posts/auth/:5:0","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"附录 ","date":"2022-09-04","objectID":"/posts/auth/:6:0","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"OAuth2.0 OAuth2.0与session、cookie机制对比 与session机制类似，OAuth2.0只是变成token，但是session有其局限性，特别是API对接。 还有一些终端默认是不带cookie的，比如Android。 OAuth2.0不是一个认证协议（是授权协议），OAuth2.0本身并不能告诉你任何用户信息。 四种授权模式 授权模式（authorization code） 正宗模式。认证时，直接将用户导向认证服务器，用户选择同意后，认证服务器向客户端发送授权码，客户端凭次授权码请求访问令牌， 申请到令牌之后授权码失效，类似通过第三方软件授权。支持refresh token。 简化模式（implicit） 比授权码模式少了授权码环节，回调url直接携带token。为Web浏览器应用设计。不支持refresh token。 密码模式（resource owner password credentials） 用户直接把帐号密码给客户端，客户端凭此帐号密码向认证服务器请求令牌。支持refresh token。 客户端模式（client credentials） 用户直接将客户端注册，客户端凭自己的名义要求认证服务提供服务。为后台API服务消费者设计。不支持refresh token。 Refresh Token机制用于获取新的Access Token，这样可以缩短Access Token的过期时间保证安全，同时又不会因为频繁过期重新要求用户登录。 ","date":"2022-09-04","objectID":"/posts/auth/:6:1","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"Token和JWT Token： 服务端验证客户端发送过来的Token时，还需要查询数据库获取用户信息。然后验证Token是否有效。 JWT： 将Token和Payload加密后存储在客户端，服务端只需要使用密钥解密进行校验（校验也是JWT自己实现的）即可，不需要查询或者减少数据的查询，因为JWT自包含了用户信息和加密的数据。 ","date":"2022-09-04","objectID":"/posts/auth/:6:2","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["“Docker”","Registry"],"content":"kid的生成 首先从RSA私钥中提取公钥，保存到文件public_key.pem中： openssl rsa -in private_key.pem -out public_key.pem -pubout 然后将公钥文件由pem格式生成der格式： openssl rsa -pubin -inform PEM -in public_key.pem -outform DER -out public_key.der 然后对der格式的公钥文件做sha256哈希： sha256sum public_key.der 3b3def0af2c85f060fb90c71494dc3105ea8b5a5bfc822ae0b5c89a54152e706 去掉十六进制的哈希值后四位得到： 3b3def0af2c85f060fb90c71494dc3105ea8b5a5bfc822ae0b5c89a54152 然后用base32（RFC4648）进行编码（base32在线编码网址），编码后得到： HM666CXSZBPQMD5ZBRYUSTODCBPKRNNFX7ECFLQLLSE2KQKS 每四位一组，中间用:隔开，得到kid的值 HM66:6CXS:ZBPQ:MD5Z:BRYU:STOD:CBPK:RNNF:X7EC:FLQL:LSE2:KQKS ","date":"2022-09-04","objectID":"/posts/auth/:6:3","tags":["Docker","Registry"],"title":"Registry 认证和授权","uri":"/posts/auth/"},{"categories":["Hugo"],"content":"注册 前往官方网站使用GitHub或Google帐号登录。登录完成后根据提示信息填写一些基本的信息即可，注册完成后前往Overview，我们可以发现Algolia会默认给我们生成一个APP。该APP下有API Keys信息。 在【Data sources】 -\u003e【Indices】中新建index。 Algolia 为我们提供了三种方式来增加记录： 手动添加 上传json文件 API 我们这里使用API方式来进行数据的添加。 ","date":"2022-08-24","objectID":"/posts/algolia/:1:0","tags":["Hugo"],"title":"Algolia 站内搜索","uri":"/posts/algolia/"},{"categories":["Hugo"],"content":"API插件 要使用API的方式来添加搜索的数据，我们可以自己根据Algolia提供的API文档进行开发，这也是很容易的，为简单起见，我们这里使用一个hugo-algolia的插件来完成我们的数据同步工作。 Tip 要安装hugo-aligolia我们需要先确保我们已经安装了npm或者yarn包管理工具。 安装hugo-aligolia： npm install hugo-algolia -g 安装完成后，在我们hugo生产的静态页面的根目录下面新建一个config.yaml的文件(和config.toml同级)，然后在config.yaml文件中指定Algolia相关的API数据。 ---baseurl:\"blog.huangjingwei.site\"DefaultContentLanguage:\"zh-cn\"hasCJKLanguage:truelanguageCode:\"zh-cn\"title:\"wall-e's craft\"theme:\"LoveIt\"metaDataFormat:\"yaml\"algolia:index:\"blog.huangjingwei.site\"key:\"********\"appID:\"********\"--- 以上配置文件中的index，key，appID的值要和API Keys的信息一致。 配置完成以后，在根目录下面执行下面的命令： $ hugo-algolia -s JSON index file was created in public/algolia.json { updatedAt: '2018-02-23T02:36:09.480Z', taskID: 249063848950 } 然后我们可以看到，上面命令执行完成后会在public目录下面生成一个algolia.json的文件。在官方网站打开Indices，可以看到已经有几十条数据了。 如果某篇文章不想被索引的话，我们只需要在文件的最前面设置index参数为false即可，hugo-algolia插件在索引的过程中会自动跳过它。 ","date":"2022-08-24","objectID":"/posts/algolia/:2:0","tags":["Hugo"],"title":"Algolia 站内搜索","uri":"/posts/algolia/"},{"categories":["Hugo"],"content":"站点配置 以LoveIt主题为例，在config.yaml中修改搜索相关的配置，将搜索引擎配置为algolia，并根据实际补充相关配置参数。 [languages.zh-cn.params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"algolia\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"只支持首页搜索\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [languages.zh-cn.params.search.algolia] index = \"blog.huangjingwei.site\" appID = \"********\" searchKey = \"\"********\" placeholder = \"只支持首页搜索\"，目前未解决。 ","date":"2022-08-24","objectID":"/posts/algolia/:3:0","tags":["Hugo"],"title":"Algolia 站内搜索","uri":"/posts/algolia/"},{"categories":["Hugo"],"content":"附录 站内搜索插件 ","date":"2022-08-24","objectID":"/posts/algolia/:4:0","tags":["Hugo"],"title":"Algolia 站内搜索","uri":"/posts/algolia/"},{"categories":["Kubernetes"],"content":"安装kubeadm三件套 三件套： kubeadm：用来初始化集群的指令。 kubelet：运行在集群节点上的组件。 kubectl：和集群交互的CLI客户端。 ","date":"2022-08-14","objectID":"/posts/install/:1:0","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"官方源安装 sudo apt-get update \u0026\u0026 sudo apt-get install -y apt-transport-https curl curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - cat \u003c\u003cEOF | sudo tee /etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF sudo apt-get update sudo apt-get install -y kubelet kubeadm kubectl sudo apt-mark hold kubelet kubeadm kubectl #固定其版本 参考官方安装教材法文版。 ","date":"2022-08-14","objectID":"/posts/install/:1:1","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"国内源安装 cat \u003c\u003cEOF \u003e /etc/apt/sources.list.d/kubernetes.list deb http://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial main EOF sudo apt-get update 添加源之后，执行 apt-get update报错。原因是没有公钥，无法验证签名。添加操作可以执行下面的命令，命令中的BA07F4FB为报错信息中提示的缺失公钥的后8位。 gpg --keyserver keyserver.ubuntu.com --recv-keys BA07F4FB gpg --export --armor E084DAB9 | sudo apt-key add - 安装 sudo apt-get install -y kubectl kubeadm kubectl ","date":"2022-08-14","objectID":"/posts/install/:1:2","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"命令自动补全 kubectl completion bash \u003e kubectl sudo mv kubectl /etc/bash_completion.d/ kubeadm completion bash \u003e kubeadm sudo mv kubeadm /etc/bash_completion.d/ ","date":"2022-08-14","objectID":"/posts/install/:1:3","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"禁用swap 如果在安装系统的时候分配了swap。需要将其关闭。 sudo swapoff -a #查看 free -h ","date":"2022-08-14","objectID":"/posts/install/:2:0","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"创建集群 kubeadm config images pull #pull Google提供的相关镜像。 sudo kubeadm init #初始化并创建Kubernetes集群。 如果是国内的网络，镜像拉取会失败。 配置代理拉取google镜像：dockerd代理配置 使用阿里的镜像： kubeadm config image pull --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers ","date":"2022-08-14","objectID":"/posts/install/:3:0","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"Kuberneres v1.24 适配docker 在Kubernetes v1.24及更早版本中，依然可以通过dockershim来使用Docker Engine。 但是dockershim组件在Kubernetes v1.24发行版本中已被移除。 不过，可以通过配置容器运行时接口CRI使用cri-dockerd。 ","date":"2022-08-14","objectID":"/posts/install/:4:0","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"安装cri-dockerd wget https://github.com/Mirantis/cri-dockerd/releases/download/v0.2.5/cri-dockerd_0.2.5.3-0.ubuntu-jammy_amd64.deb sudo dpkg -i cri-dockerd_0.2.5.3-0.ubuntu-jammy_amd64.deb 推荐在Release中找到最新版本下载安装。 ","date":"2022-08-14","objectID":"/posts/install/:4:1","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"修改kubeadm配置 $ kubeadm config print init-defaults apiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 1.2.3.4 bindPort: 6443 nodeRegistration: criSocket: unix:///var/run/containerd/containerd.sock imagePullPolicy: IfNotPresent name: node taints: null --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: k8s.gcr.io kind: ClusterConfiguration kubernetesVersion: 1.24.0 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 scheduler: {} 将以上配置文件写入文件，并修改其内容。 kubeadm config print init-defaults \u003e init.yaml # 修改init.yaml: apiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 192.168.3.6 #本机ip bindPort: 6443 nodeRegistration: criSocket: unix:///run/cri-dockerd.sock #改成cri-dockerd imagePullPolicy: IfNotPresent name: walle #本机hostname taints: null --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: k8s.gcr.io # 这里也可以改成阿里的惊喜 kind: ClusterConfiguration kubernetesVersion: 1.24.0 networking: dnsDomain: cluster.local serviceSubnet: 10.172.0.0/12 podSubnet: 10.244.0.0/16 # --pod-network-cidr Specify range of IP addresses for the pod network. If set, the control plane will automatically allocate CIDRs for every node. scheduler: {} sudo kubeadm init --config init.yaml # 如果在命令后面指定--pod-network-cidr则会报“can not mix '--config' with arguments [pod-network-cidr]“，参考：https://github.com/kubernetes/kubeadm/issues/1899 ","date":"2022-08-14","objectID":"/posts/install/:4:2","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"配置kubectl客户端 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 配置完，kubectl在当前用户就可以用了。 $ kubectl --namespace=kube-system get pods NAME READY STATUS RESTARTS AGE coredns-6d4b75cb6d-lvct9 1/1 ContainerCreating 0 31s coredns-6d4b75cb6d-zpwcc 1/1 ContainerCreating 0 31s etcd-walle 1/1 Running 0 31s kube-apiserver-walle 1/1 Running 0 31s kube-controller-manager-walle 1/1 Running 0 31s kube-proxy-rbgzm 1/1 Running 0 31s kube-scheduler-walle 1/1 Running 0 31s 在未配置网络插件（CNI Plugin）时，可以发现coredns是无法启动的。 ","date":"2022-08-14","objectID":"/posts/install/:5:0","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"网络插件配置 如果之前安装过其他的插件，需要先清理配置： sudo rm -f /etc/cni/net.d/* ","date":"2022-08-14","objectID":"/posts/install/:6:0","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"安装flannel 执行命令安装flannel： kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml 安装后所有的Pod都正常启动 $ kubectl --namespace=kube-system get pods NAME READY STATUS RESTARTS AGE coredns-6d4b75cb6d-lvct9 1/1 Running 0 9h coredns-6d4b75cb6d-zpwcc 1/1 Running 0 9h etcd-walle 1/1 Running 0 9h kube-apiserver-walle 1/1 Running 0 9h kube-controller-manager-walle 1/1 Running 0 9h kube-proxy-rbgzm 1/1 Running 0 9h kube-scheduler-walle 1/1 Running 0 9h ","date":"2022-08-14","objectID":"/posts/install/:6:1","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"检查podCIDR配置 $ kubectl get node -o yaml | grep CIDR podCIDR: 10.244.0.0/24 podCIDRs: ","date":"2022-08-14","objectID":"/posts/install/:6:2","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Kubernetes"],"content":"master 节点默认不能运行 pod 如果用 kubeadm 部署一个单节点集群，默认情况下无法使用，请执行以下命令解除限制 $ kubectl taint nodes --all node-role.kubernetes.io/master- # 恢复默认值 # $ kubectl taint nodes NODE_NAME node-role.kubernetes.io/master=true:NoSchedule ","date":"2022-08-14","objectID":"/posts/install/:7:0","tags":["Kubernetes"],"title":"Kubernetes 安装","uri":"/posts/install/"},{"categories":["Ubuntu"],"content":" 使用花生壳，实现内网穿透，以便在公网的机器可以正确路由到内网的主机上的服务。 ","date":"2022-06-05","objectID":"/posts/phddns/:0:0","tags":["Ubuntu"],"title":"花生壳内网穿透","uri":"/posts/phddns/"},{"categories":["Ubuntu"],"content":"安装和卸载 S wget \"https://down.oray.com/hsk/linux/phddns_5.2.0_amd64.deb\" -O phddns_5.2.0_amd64.deb $ sudo dpkg -i phddns_5.2.0_amd64.deb #安装 $ sudo dpkg -r phddns #卸载 ","date":"2022-06-05","objectID":"/posts/phddns/:1:0","tags":["Ubuntu"],"title":"花生壳内网穿透","uri":"/posts/phddns/"},{"categories":["Ubuntu"],"content":"运行 $ phddns Phtunnel Serive called with unknown argument (phddns |start|status|stop|restart|reset|enable|disable|version) $ phddns status +--------------------------------------------------+ | Oray PeanutHull Linux 5.2.0 | +--------------------------------------------------+ | Runstatus: ONLINE | +--------------------------------------------------+ | SN: oray************ | +--------------------------------------------------+ | Remote Management Address http://b.oray.com | +--------------------------------------------------+ ","date":"2022-06-05","objectID":"/posts/phddns/:2:0","tags":["Ubuntu"],"title":"花生壳内网穿透","uri":"/posts/phddns/"},{"categories":["Ubuntu"],"content":"SN码激活 phddns status会提示有远程的管理地址：http://b.oray.com,选择SN登录。 帐号在phddns status指令返回，登录的初始密码为admin。 首次登录，需先激活。所以需要注册贝锐的管理帐号用于以上SN码激活，注册地址：注册帐号。 激活成功后，再用SN码登录时，密码自动更改为贝锐的管理帐号的密码。 ","date":"2022-06-05","objectID":"/posts/phddns/:3:0","tags":["Ubuntu"],"title":"花生壳内网穿透","uri":"/posts/phddns/"},{"categories":["Ubuntu"],"content":"TCP添加映射 进入花生壳管理平台。若绑定SN码的帐号只有动态域名解析功能，需使用内网穿透功能时，可点击“免费开通”，或直接将帐号升级到带内网穿透功能的服务版本。 添加内网穿透映射时，点击页面上的增加映射按钮。 根据页面提示填写映射所需的信息，这里以映射Ubuntu系统的SSH服务（22端口）为例： ①应用名称：自定义 ②应用图标：自行选择 ③映射类型：选择TCP ④映射模板：暂不选择模板 ⑤外网域名：选择用作外网访问的域名，域名是平台默认生成，这时候应该有个默认域名可供选择。 ⑥外网端口：选择动态端口 ⑦内网主机：映射的Ubuntu系统内网IP地址 ⑧内网端口：映射的服务类型对应端口22 ⑨带宽：购买映射带宽后，可支持给映射分配额外带宽，这里保存默认。 确认映射内容无误后，点击“确定”。 Tip 查看当前的ubuntu是否安装了ssh-server服务。默认只安装ssh-client服务。 dpkg -l | grep ssh 如果没有openssh-server，安装： sudo apt-get install openssh-server 这样在外网的电脑上，打开连接SSH服务的工具程序，输入域名与外网端口号就可以访问了。 ","date":"2022-06-05","objectID":"/posts/phddns/:4:0","tags":["Ubuntu"],"title":"花生壳内网穿透","uri":"/posts/phddns/"},{"categories":["Ubuntu"],"content":"HTTP添加映射 HTTP映射和TCP映射大同小异，只不过要向平台缴费￥6，然后等平台给一个新的域名。 建议端口号用默认的就可以，然后内网ip和端口按实际的填写。可以开启限制访问。 ","date":"2022-06-05","objectID":"/posts/phddns/:5:0","tags":["Ubuntu"],"title":"花生壳内网穿透","uri":"/posts/phddns/"},{"categories":["Ubuntu"],"content":"远程桌面 以Windows远程Ubuntu桌面为例。 Windows的mstsc远程桌面支持远程桌面协议 (RDP)， Xrdp是一个开源工具，允许用户通过Windows RDP访问Linux远程桌面。 Ubuntu按照xrdp： sudo apt install xrdp sudo systemctl enable xrdp sudo adduser xrdp ssl-cert sudo systrmctl restart xrdp xrdp默认使用/etc/ssl/private/ssl-cert-snakeoil.key，该文件ssl-cert组里的用户是只读的。 Tip 在远程桌面前，最好退出其他有在登录的用户，避免黑屏。 $ sudo systemctl status xrdp ● xrdp.service - xrdp daemon Loaded: loaded (/lib/systemd/system/xrdp.service; enabled; vendor preset: enabled) Active: active (running) since Wed 2022-08-31 22:47:17 CST; 2s ago Docs: man:xrdp(8) man:xrdp.ini(5) Process: 17618 ExecStartPre=/bin/sh /usr/share/xrdp/socksetup (code=exited, status=0/SUCCESS) Process: 17626 ExecStart=/usr/sbin/xrdp $XRDP_OPTIONS (code=exited, status=0/SUCCESS) Main PID: 17627 (xrdp) Tasks: 1 (limit: 38360) Memory: 872.0K CPU: 11ms CGroup: /system.slice/xrdp.service └─17627 /usr/sbin/xrdp 8月 31 22:47:16 walle systemd[1]: Starting xrdp daemon... 8月 31 22:47:16 walle xrdp[17626]: [INFO ] address [0.0.0.0] port [3389] mode 1 8月 31 22:47:16 walle xrdp[17626]: [INFO ] listening to port 3389 on 0.0.0.0 8月 31 22:47:16 walle xrdp[17626]: [INFO ] xrdp_listen_pp done 8月 31 22:47:16 walle systemd[1]: xrdp.service: Can't open PID file /run/xrdp/xrdp.pid (yet?) after start: Operation not permitted 8月 31 22:47:17 walle systemd[1]: Started xrdp daemon. 8月 31 22:47:18 walle xrdp[17627]: [INFO ] starting xrdp with pid 17627 8月 31 22:47:18 walle xrdp[17627]: [INFO ] address [0.0.0.0] port [3389] mode 1 8月 31 22:47:18 walle xrdp[17627]: [INFO ] listening to port 3389 on 0.0.0.0 8月 31 22:47:18 walle xrdp[17627]: [INFO ] xrdp_listen_pp done 由此可以看出，xrdp的默认端口是3389。花生壳上添加tcp的映射方式，内网端口就是xrdp的端口号。 xrdp在局域网中可以延时很低，但是在通过花生壳在公网中访问会非常卡顿。 这里有个临时解决方案： 在Windows远程桌面时，选择显示选项： 体验 -\u003e 选择链接速度来优化性能（调制解调器56Kbps。 显示 -\u003e 选择桌面的大小（1024×768。 ","date":"2022-06-05","objectID":"/posts/phddns/:6:0","tags":["Ubuntu"],"title":"花生壳内网穿透","uri":"/posts/phddns/"},{"categories":["Ubuntu"],"content":"总结 对于个人用户，部署友好，3步创建映射，一键内网穿透无需公网IP，无需搭建专线。 但毕竟是商业平台，最多支持2个映射关系。 如果想添加更多的映射，配置相关安全策略，或者在性能上有需求等都是需要付费的。 尊重产权，适当氪金。 ","date":"2022-06-05","objectID":"/posts/phddns/:7:0","tags":["Ubuntu"],"title":"花生壳内网穿透","uri":"/posts/phddns/"},{"categories":["Ubuntu"],"content":"附录 花生壳5.0 for Linux使用教程 ","date":"2022-06-05","objectID":"/posts/phddns/:8:0","tags":["Ubuntu"],"title":"花生壳内网穿透","uri":"/posts/phddns/"},{"categories":["Hugo"],"content":" klakegg/hugo是官方推荐的，包含hugo开源静态网站生成器的镜像。 ","date":"2022-06-05","objectID":"/posts/image/:0:0","tags":["Hugo"],"title":"使用hugo镜像","uri":"/posts/image/"},{"categories":["Hugo"],"content":"docker-compose version:'3'services:hugo:container_name:\"×××.github.io\"image:\"klakegg/hugo:latest\"ports:- \"1313:1313\"volumes:- \"~/×××.github.io.source:/×××.github.io.source\"working_dir:\"/×××.github.io.source\"command:[\"server\",\"-D\"] ","date":"2022-06-05","objectID":"/posts/image/:1:0","tags":["Hugo"],"title":"使用hugo镜像","uri":"/posts/image/"},{"categories":["Hugo"],"content":"使用hugo 启动服务： docker-compose up -d 启动服务之后就会有相关容器在运行。 如果要新建博文： docker exec -it ${container_id} hugo new content/posts/Ubuntu/test.md 以上面为例，可以调用hugo的其他命令。 ","date":"2022-06-05","objectID":"/posts/image/:2:0","tags":["Hugo"],"title":"使用hugo镜像","uri":"/posts/image/"},{"categories":["Ubuntu"],"content":"双系统卸载Ubuntu 在安装双系统的惯用手法是，在Windows下的磁盘管理中压缩出可用空间用于安装Ubuntu。 所以删除系统就是在磁盘管理中把对应的Ubuntu的卷删除即可。 Ubuntu的卷是在其安装的时候，划分空间的时候生成的，如果你划分了/boot， 那么磁盘管理中会有一个EFI 系统分区的的卷，用于存放系统内核，Windows系统也会有此卷的，删除的时候需谨慎区分。 通常在安装双系统的时候，会有系统引导项。在Ubuntu系统安装成功后，一般会有GNU GRUB作为多系统的启动管理器。 该管理器是可在Windows的EFI 系统分区的卷中删除。 打开CMD命令提示符窗口，键入diskpart（磁盘分区管理工具）。然后依图行事， 将Windows的EFI 系统分区的卷赋予一个与已有盘符不冲突的盘符（这里用P来表示）。 退出diskpart。进入P盘，如下图路径，在EFI文件夹下找到ubuntu,并将此删除。 最后重新回到diskpart。删去P盘的盘符即可。 这样就完成了GNU GRUB引导项的卸载。 如果没有删除直接启动电脑，引导项将无法正常工作： 这时候，可以在BIOS改变下启动次序，优先启动Windows系统，然后进去再按照上述操作把残留的Ubuntu系统引导工具删去。 ","date":"2022-05-23","objectID":"/posts/instatll/:1:0","tags":["Ubuntu"],"title":"Ubuntu 卸载和安装","uri":"/posts/instatll/"},{"categories":["Ubuntu"],"content":"安装Ubuntu Windows和Ubuntu双系统的安装的问题记录。 ","date":"2022-05-23","objectID":"/posts/instatll/:2:0","tags":["Ubuntu"],"title":"Ubuntu 卸载和安装","uri":"/posts/instatll/"},{"categories":["Ubuntu"],"content":"分区问题 在自定义安装Ubuntu系统的时候，会有分区的选择。以前分区的时候会给/boot，swap,/,/home分配大小。 以前的系统都推荐给/boot分配100M左右的大小即可，主要要于放置系统的内核，但是随着系统越来越大， 并且最新的内核已将视频模式设置已入内核，详见下文安装黑屏问题，所以之前的分区大小是不够的。 /目录相当于Windows的C盘，主要放置系统，如果想留有余量一般会规划个30G左右。 /home放置用户的文件，所以剩余的空间都是该目录下的。 swap分区，在系统的物理内存不够用的情况下回把硬盘的空间释放出来供当前运行的程序使用，一般都是推荐是内存的两倍大小。 如果内存够大，其实不用使用太多的swap分区，可以通过修改swappiness的数值来调整使用内存和swap的策略。 0代表最大程度使用物理内存，100则表示优先swap分区。如果想要调整swappiness的大小，可在/etc/sysctl.conf添加： vm.swappiness=0 查看内存和swap分区的使用情况。 free -h 推荐的分区策略是：现在的机器内存够大，一般无需规划swap分区，其余的空闲大小都分给/目录。 ","date":"2022-05-23","objectID":"/posts/instatll/:2:1","tags":["Ubuntu"],"title":"Ubuntu 卸载和安装","uri":"/posts/instatll/"},{"categories":["Ubuntu"],"content":"安装黑屏问题 黑屏原因 在x服务器启动时，所有针对硬件的时钟速率和视频卡上的寄存器的编程都在内核中进行， 而不是在x驱动器中进行，这样做的目的是为了从启动画面到登录画面的过渡拥有更高的分辨率和漂亮的启动屏幕并且无闪烁。 但是有的卡就是不行，所以伺候你一个黑屏。 nomodeset The newest kernels have moved the video mode setting into the kernel. So all the programming of the hardware specific clock rates and registers on the video card happen in the kernel rather than in the X driver when the X server starts. This makes it possible to have high resolution nice looking splash (boot) screens and flicker free transitions from boot splash to login screen. Unfortunately, on some cards this doesnt work properly and you end up with a black screen. Adding the nomodeset parameter instructs the kernel to not load video drivers and use BIOS modes instead until X is loaded. Note that this option is sometimes needed for nVidia cards when using the default “nouveau” drivers. Installing proprietary nvidia drivers usually makes this option no longer necessary, so it may not be needed to make this option permanent, just for one boot until you installed the nvidia quiet This option tells the kernel to NOT produce any output (a.k.a. Non verbose mode). If you boot without this option, you’ll see lots of kernel messages such as drivers/modules activations, filesystem checks and errors. Not having the quiet parameter may be useful when you need to find an splash This option is used to start an eye-candy “loading” screen while all the core parts of the system are loaded in the background. If you disable it and have quiet enable you’ll get a blank screen. 参考Why do I need to replace “quiet splash” with “nomodeset”? 设置内核引导选项 1.系统安装出现黑屏 选择install ubuntu后，按e进入编辑模式，进入命令行模式, 在quiet splash 前面添加nomodeset。然后F10继续安装。 Intel 82852/82855 或8系列显示晶片：i915.modeset=1或i915.modeset=0 Nvidia：nomodeset 其它厂牌(如ATI，技嘉)：xforcevesa或radeon.modeset=0 xforcevesa 2.启动系统出现黑画面 选择ubuntu后，按e进入编辑模式，进入命令行模式, 在quiet splash 后面添加nomodeset。然后F10继续安装。 3.永久设置 进去系统之后编辑/etc/default/grub(要管理者权限sudo)。 在GRUB_CMDLINE_LINUX_DEFAULT中添加nomodeset。如下： GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash nomodeset\" 更新GRUB： sudo update-grub 然后重启。 ","date":"2022-05-23","objectID":"/posts/instatll/:2:2","tags":["Ubuntu"],"title":"Ubuntu 卸载和安装","uri":"/posts/instatll/"},{"categories":["Ubuntu"],"content":"init=/bin/bash内核特性 这个特性主要用于恢复系统或者修改密码。 在GNU GRUB引导进入系统的是，按e进入编辑模式，在linux的行尾添加init=/bin/bash，然后F10启动。 进入系统后可能要读写某个文件，会遇到Reas-only file system的情况。可以将上面的命令改为rw init=/bin/bash。 或者： mount -o remount -rw / 恢复的指令为： mount -o remount -r / ","date":"2022-05-23","objectID":"/posts/instatll/:2:3","tags":["Ubuntu"],"title":"Ubuntu 卸载和安装","uri":"/posts/instatll/"},{"categories":["Ubuntu"],"content":"科学上网 当然有商业软件VPN，这类产品稳定、支持多平台，但是价格也略高。 机场包括免费分享机场、付费机场订阅和自建机场。 免费分享机场不够稳定，质量也参差不齐，时间成本高。 自建机场需要买海外的主机，价格也不便宜，ip也容易被封。 我现在使用的是付费机场云翼，可点击邀请链接进入注册。 下图是这个机场提供的订阅方式： 这里我们使用clash for Windows的上网软件，该软件可支持Windows、macOS、Linux系统。 在Releases中下载安装包，Ubuntu系统下载tag.gz即可，但是v0.19.18有gnome-shell内存泄漏，要避免使用该版本。 下载完成解压，并在解压路径下运行./cfw运行软件。 在机场中复制Clash_V2Ray订阅链接，并粘贴到clash for Windows的【Profiles】的下载位置下载节点列表。 这样就可以科学上网了。 ","date":"2022-05-23","objectID":"/posts/instatll/:3:0","tags":["Ubuntu"],"title":"Ubuntu 卸载和安装","uri":"/posts/instatll/"},{"categories":["Python"],"content":" Pipenv是Python项目的依赖管理器。尽管pip可以安装Python包，但仍推荐使用Pipenv，因为它是一种更高级的工具，可简化依赖关系管理的常见使用情况。 ","date":"2022-03-05","objectID":"/posts/pipenv-usage/:0:0","tags":["Python"],"title":"Pipenv 的基本使用","uri":"/posts/pipenv-usage/"},{"categories":["Python"],"content":"1 pipenv 安装 使用pip安装： pip install --user pipenv --user代表用户安装模式，以防止破坏任何系统范围的包。 如果安装后, shell中没有pipenv，则需要将用户基础目录的二进制文件目录添加到PATH中。 Tip 在Linux和macOS上，您可以通过运行python -m site --user-base找到用户基础目录，然后把bin加到目录末尾。比如，上述命令典型地会打印出 ~/.local（~ 会扩展为您的家目录的局对路径），然后将 ~/.local/bin 添加到PATH中。 在 Windows 上，您通过运行py -m site --user-site找到用户基础目录，然后将site-packages替换为Scripts。比如，上述命令可能返回C:\\Users\\Username\\AppData\\Roaming\\Python310\\site-packages，然后您需要在PATH中包含C:\\Users\\Username\\AppData\\Roaming\\Python310\\Scripts。 ","date":"2022-03-05","objectID":"/posts/pipenv-usage/:1:0","tags":["Python"],"title":"Pipenv 的基本使用","uri":"/posts/pipenv-usage/"},{"categories":["Python"],"content":"2 创建虚拟环境 ","date":"2022-03-05","objectID":"/posts/pipenv-usage/:2:0","tags":["Python"],"title":"Pipenv 的基本使用","uri":"/posts/pipenv-usage/"},{"categories":["Python"],"content":"pipenv –python 可以指定版本创建，如果指定版本不存在: pienv --python 3.8 Warning: Python 3.8 was not found on your system... ","date":"2022-03-05","objectID":"/posts/pipenv-usage/:2:1","tags":["Python"],"title":"Pipenv 的基本使用","uri":"/posts/pipenv-usage/"},{"categories":["Python"],"content":"pipenv –three / –two 或者指定Python 3/2创建虚拟环境： pipenv --three / --two Note 以上i这两种创建指令会自动创建Pipfile，但不会有Pipfile.lock。 ","date":"2022-03-05","objectID":"/posts/pipenv-usage/:2:2","tags":["Python"],"title":"Pipenv 的基本使用","uri":"/posts/pipenv-usage/"},{"categories":["Python"],"content":"pipenv install pipenv install pipenv install --three / --two Note pipenv install在一个初始化工程中会自动创建出Pipfile和Pipfile.lock。 如果在一个已经是pipenv管理的工程中执行该命令，会在本地创建虚拟环境并自动安装Pipfile中的包。 等价指令： 1.pipenv install在新建工程中： pipenv install = pipenv --three + pipenv lock + pipenv sync 2.pipenv install在已有Pipfile的工程中： pipenv install = pipenv update = pipenv lock + pipenv sync ","date":"2022-03-05","objectID":"/posts/pipenv-usage/:2:3","tags":["Python"],"title":"Pipenv 的基本使用","uri":"/posts/pipenv-usage/"},{"categories":["Python"],"content":"3 Pipfile 和 Pipfile.lock 基于一个空项目创建的Pipfile文件内容如下： [[source]] url = \"https://pypi.org/simple\" verify_ssl = true name = \"pypi\" [packages] [dev-packages] [requires] python_version = \"3.10\" 基于pipenv install会多出一个Pipfile.lock: { \"_meta\": { \"hash\": { \"sha256\": \"fedbd2ab7afd84cf16f128af0619749267b62277b4cb6989ef16d4bef6e4eef2\" }, \"pipfile-spec\": 6, \"requires\": { \"python_version\": \"3.10\" }, \"sources\": [ { \"name\": \"pypi\", \"url\": \"https://pypi.org/simple\", \"verify_ssl\": true } ] }, \"default\": {}, \"develop\": {} } 安装package： pipenv install requests pipenv install pytest --dev Pipfile自动更新： [[source]] url = \"https://pypi.org/simple\" verify_ssl = true name = \"pypi\" [packages] requests = \"*\" [dev-packages] [requires] python_version = \"3.10\" 为限制篇幅，以下的Pipfile.lock是只安装requests的内容： { \"_meta\": { \"hash\": { \"sha256\": \"a416d48a2c30d4acf425cb96d7ac6672753db8e8f6c962a328848db5b9a290a1\" }, \"pipfile-spec\": 6, \"requires\": { \"python_version\": \"3.10\" }, \"sources\": [ { \"name\": \"pypi\", \"url\": \"https://pypi.org/simple\", \"verify_ssl\": true } ] }, \"default\": { \"certifi\": { \"hashes\": [ \"sha256:78884e7c1d4b00ce3cea67b44566851c4343c120abd683433ce934a68ea58872\", \"sha256:d62a0163eb4c2344ac042ab2bdf75399a71a2d8c7d47eac2e2ee91b9d6339569\" ], \"version\": \"==2021.10.8\" }, \"charset-normalizer\": { \"hashes\": [ \"sha256:2857e29ff0d34db842cd7ca3230549d1a697f96ee6d3fb071cfa6c7393832597\", \"sha256:6881edbebdb17b39b4eaaa821b438bf6eddffb4468cf344f09f89def34a8b1df\" ], \"markers\": \"python_version \u003e= '3'\", \"version\": \"==2.0.12\" }, \"idna\": { \"hashes\": [ \"sha256:84d9dd047ffa80596e0f246e2eab0b391788b0503584e8945f2368256d2735ff\", \"sha256:9d643ff0a55b762d5cdb124b8eaa99c66322e2157b69160bc32796e824360e6d\" ], \"markers\": \"python_version \u003e= '3'\", \"version\": \"==3.3\" }, \"requests\": { \"hashes\": [ \"sha256:68d7c56fd5a8999887728ef304a6d12edc7be74f1cfa47714fc8b414525c9a61\", \"sha256:f22fa1e554c9ddfd16e6e41ac79759e17be9e492b3587efa038054674760e72d\" ], \"index\": \"pypi\", \"version\": \"==2.27.1\" }, \"urllib3\": { \"hashes\": [ \"sha256:000ca7f471a233c2251c6c7023ee85305721bfdf18621ebff4fd17a8653427ed\", \"sha256:0e7c33d9a63e7ddfcb86780aac87befc2fbddf46c58dbb487e0855f7ceec283c\" ], \"markers\": \"python_version \u003e= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3, 3.4' and python_version \u003c '4'\", \"version\": \"==1.26.8\" } }, \"develop\": {} } 可以发现： Pipfile.lock会生成所有已下载包的sha256哈希值(包括中间依赖)。这使得pip在不安全网络情况下，保证你安装了你想要的包，或者从一个不信任的PyPI源下载依赖. 查看依赖： $ pipenv graph pytest==7.0.1 - atomicwrites [required: \u003e=1.0, installed: 1.4.0] - attrs [required: \u003e=19.2.0, installed: 21.4.0] - colorama [required: Any, installed: 0.4.4] - iniconfig [required: Any, installed: 1.1.1] - packaging [required: Any, installed: 21.3] - pyparsing [required: \u003e=2.0.2,!=3.0.5, installed: 3.0.7] - pluggy [required: \u003e=0.12,\u003c2.0, installed: 1.0.0] - py [required: \u003e=1.8.2, installed: 1.11.0] - tomli [required: \u003e=1.0.0, installed: 2.0.1] requests==2.27.1 - certifi [required: \u003e=2017.4.17, installed: 2021.10.8] - charset-normalizer [required: ~=2.0.0, installed: 2.0.12] - idna [required: \u003e=2.5,\u003c4, installed: 3.3] - urllib3 [required: \u003e=1.21.1,\u003c1.27, installed: 1.26.8] requests的依赖有certifi、charset-normalizer、idna、urllib3，这些信息同样被记录在Pipfile.lock。 ","date":"2022-03-05","objectID":"/posts/pipenv-usage/:3:0","tags":["Python"],"title":"Pipenv 的基本使用","uri":"/posts/pipenv-usage/"},{"categories":["Python"],"content":"4 版本管理 官方建议： Generally, keep both Pipfile and Pipfile.lock in version control. Do not keep Pipfile.lock in version control if multiple versions of Python are being targeted. 参照#598。有个观点时Pipfile.lock可以精准控制中间依赖的版本，我参与的项目是将Pipfile.lock一并纳入版本管理。 ","date":"2022-03-05","objectID":"/posts/pipenv-usage/:4:0","tags":["Python"],"title":"Pipenv 的基本使用","uri":"/posts/pipenv-usage/"},{"categories":["Python"],"content":"5 可修改依赖 (如 -e . ) 你可以让Pipenv以可修改模式安装某个路径，通常用于开发Python包时，安装当前工作目录。 $ pipenv install --dev -e . $ cat Pipfile [dev-packages] \"e1839a8\" = {path = \".\", editable = true} 所有次级依赖也会加到Pipfile.lock中。如果没有加-e选项次级依赖将不会加到Pipfile.lock中。 ","date":"2022-03-05","objectID":"/posts/pipenv-usage/:5:0","tags":["Python"],"title":"Pipenv 的基本使用","uri":"/posts/pipenv-usage/"},{"categories":["Python"],"content":"6 使用pipenv进行部署 可以用pipenv进行部署，在运行环境中安装Pipfile.lock中得依赖。 pipenv install --deploy pipenv sync 相关操作澄清： pipenv install --deploy是直接通过Pipfile.lock安装的，当Pipfile.lock的package版本过时或者python版本不对时，会失败。 pienv install --deploy和pipenv install的区别在于后者是以Pipfile安装的，如果package未指定版本时或者有新的package，会重新lock生成新的Pipfile.lock。 pipenv sync是直接根据Pipfile.lock中的依赖版本准确安装。 pipenv install --ignore-pipfile类似pipenv sync有点类似，只依赖Pipfile.lock。但是前者会re-lock，如Pipfile.lock中的package版本过时，会被更新。 ","date":"2022-03-05","objectID":"/posts/pipenv-usage/:6:0","tags":["Python"],"title":"Pipenv 的基本使用","uri":"/posts/pipenv-usage/"},{"categories":["Python"],"content":"7 Pipfile vs setup.py 详见：Pipfile vs setup.py。 可以通过以下命令将setup.py中的相关依赖安装到你的虚拟环境和Pipfile中。 pipenv install -e . ","date":"2022-03-05","objectID":"/posts/pipenv-usage/:7:0","tags":["Python"],"title":"Pipenv 的基本使用","uri":"/posts/pipenv-usage/"},{"categories":["Hugo"],"content":"Google Analytics Google分析（Google Analytics）是一个由Google所提供的网站流量统计服务。Google 分析（Analytics）现在是互联网上使用最广泛的网络分析服务。 ","date":"2022-02-28","objectID":"/posts/google-aualytics/:1:0","tags":["Hugo"],"title":"Hugo 配置Google Analytics和Search Console","uri":"/posts/google-aualytics/"},{"categories":["Hugo"],"content":"账号注册 在google Analytics上完成账号注册。 ","date":"2022-02-28","objectID":"/posts/google-aualytics/:1:1","tags":["Hugo"],"title":"Hugo 配置Google Analytics和Search Console","uri":"/posts/google-aualytics/"},{"categories":["Hugo"],"content":"创建网络媒体资源 在【管理】【创建网络媒体资源】下，点击【显示高级选项】。 开启【创建 Universal Analytics 媒体资源】，填写网站网址，选择【仅创建 Universal Analytics 媒体资源】， 完成网络媒体资源创建。 ","date":"2022-02-28","objectID":"/posts/google-aualytics/:1:2","tags":["Hugo"],"title":"Hugo 配置Google Analytics和Search Console","uri":"/posts/google-aualytics/"},{"categories":["Hugo"],"content":"获取跟踪信息 获取跟踪信息的导航为：【管理】【跟踪信息】【跟踪代码】。有效跟踪信息如下： 跟踪id 全局网站代码 (gtag.js) ","date":"2022-02-28","objectID":"/posts/google-aualytics/:1:3","tags":["Hugo"],"title":"Hugo 配置Google Analytics和Search Console","uri":"/posts/google-aualytics/"},{"categories":["Hugo"],"content":"hugo配置跟踪信息 需要配置的内容： config.toml中配置跟踪id 在每个网页的index.html中的head标签里添加全局网站代码（gtag.js） ","date":"2022-02-28","objectID":"/posts/google-aualytics/:2:0","tags":["Hugo"],"title":"Hugo 配置Google Analytics和Search Console","uri":"/posts/google-aualytics/"},{"categories":["Hugo"],"content":"配置跟踪id 在config.toml中找到google Analytics，并赋值为跟踪id。 googleAnalytics = \"UA-XXXXXXXXX-1\" 其中的UA-XXXXXXXXX-1需要替换成对应资源的跟踪id。 ","date":"2022-02-28","objectID":"/posts/google-aualytics/:2:1","tags":["Hugo"],"title":"Hugo 配置Google Analytics和Search Console","uri":"/posts/google-aualytics/"},{"categories":["Hugo"],"content":"配置gtag.js 在基础模板页中添加全局网站代码（gtag.js）。配置参考：Configure Google Analytics。 在项目根目录下新建layouts,在新增一个_internal/google_analytics_async.html，内容为全局网站代码（gtag.js）。 hugo规定内间模板的文件目录优先级大于主题目录，这样可以不用去更改主题下的配置模板。 这里已知有两种情况： 基础模板通过baseof.html配置。 基础模板通过head.html配置。 如果是通过baseof.html配置，需复制主题下的/themes/xxx/layouts/_default到根目录下的layouts下，不同的主题的_default下的文件可能略有不同。 +---layouts | +---_default | | | baseof.html | | | section.html | | | single.html | | | single.md | | | summary.html | \\---_internal | google_analytics_async.html 如果是head.html配置，head.html应该在/themes/xxx/layouts/partials/下，所以根目录下的layouts文件结果如下; +---layouts | +---partials | | | head.html | \\---_internal | google_analytics_async.html 无论是baseof.html还是head.html，都是在head标签内添加内容： {{- if not .Site.IsServer }} {{ template \"_internal/google_analytics_async.html\" . }} {{- end }} 验证gtag.js的内容是否成功插入，在项目根目录下执行hugo或者hugo --gc。会在根目录下会有public文件生成。查看文件夹下的index.html的head标签内是否成功插入gtag.js的内容。 ","date":"2022-02-28","objectID":"/posts/google-aualytics/:2:2","tags":["Hugo"],"title":"Hugo 配置Google Analytics和Search Console","uri":"/posts/google-aualytics/"},{"categories":["Hugo"],"content":"3 Search Console 在Search Console添加资源并提交验证。选择【网络前缀】，因为已经配置过Google Analytics,所以会自动通过谷歌分析完成所有权验证。 ","date":"2022-02-28","objectID":"/posts/google-aualytics/:3:0","tags":["Hugo"],"title":"Hugo 配置Google Analytics和Search Console","uri":"/posts/google-aualytics/"},{"categories":["Hugo"],"content":"4 提交站点地图 在Search Console中【站点地图】，添加新的站点地图，hugo会自动生成sitemap.xml，直接填写并提交即可。我提交后的状态是无法获取，暂未解决。但是可以先通过网址检查，并请求编入索引。然后通过site:example.com可以查询是否被成功索引。 ","date":"2022-02-28","objectID":"/posts/google-aualytics/:4:0","tags":["Hugo"],"title":"Hugo 配置Google Analytics和Search Console","uri":"/posts/google-aualytics/"},{"categories":["Git"],"content":"1 网络代理 git下载代码的时候可以通过https或ssh。有时候拉取GitHub上的代码因为网络原因出现失败，我们可以通过配置网络代理解决。 二者在提交代码时的认证方式不同： https：账号和密码认证。 ssh：证书认证。 ","date":"2022-02-24","objectID":"/posts/proxy/:1:0","tags":["Git"],"title":"Git 网络代理","uri":"/posts/proxy/"},{"categories":["Git"],"content":"HTTPS git config --global http.proxy \"http://127.0.0.1:3128\" git config --global https.proxy \"http://127.0.0.1:3128\" 以上配置生效会在用户目录下的.gitconfig文件中体现。 [user] name = huangjingwei email = example.com [http] proxy = http://127.0.0.1:3128 [https] proxy = http://127.0.0.1:3128 ","date":"2022-02-24","objectID":"/posts/proxy/:1:1","tags":["Git"],"title":"Git 网络代理","uri":"/posts/proxy/"},{"categories":["Git"],"content":"SSH 在用户目录下，新建.ssh/config。 Host github.com User git IdentityFile \"C:\\Users\\your-username\\.ssh\\id_rsa\" ProxyCommand connect.exe -H 127.0.0.1:3128 %h %p ","date":"2022-02-24","objectID":"/posts/proxy/:1:2","tags":["Git"],"title":"Git 网络代理","uri":"/posts/proxy/"},{"categories":["Docker"],"content":"1 Docker Docker是一个开放平台，可用于容器镜像的开发、交付和运行。 Docker名词一般是泛指。一般会代指Docker引擎(Docker Engine)或Docker注册中心(Docker registry)。 我们这边讨论的是Docker引擎。其主要有3部分组成： Docker守护进程(Docker daemon / dockerd)。 Docker Engine API。 Docker 客户端。 ","date":"2021-11-07","objectID":"/posts/proxy/:1:0","tags":["Docker"],"title":"Docker 安装和网络代理","uri":"/posts/proxy/"},{"categories":["Docker"],"content":"2 Docker的安装卸载 Docker的版本自17.03后分为CE(Community Edition)和EE(Enterprise Edition)，个人使用安装CE版本。 ","date":"2021-11-07","objectID":"/posts/proxy/:2:0","tags":["Docker"],"title":"Docker 安装和网络代理","uri":"/posts/proxy/"},{"categories":["Docker"],"content":"推荐安装方法 Linux的发行版一般会自带docker的软件包或者下载.deb文件手动安装， 但是本文推荐的安装方法是通过apt包管理工具安装，参照官网安装向导。 安装之前建议先卸载旧版本： sudo apt-get remove docker docker-engine docker.io containerd runc 添加使用HTTPS传输的软件包和CA证书： $ sudo apt-get update $ sudo apt-get install \\ ca-certificates \\ curl \\ gnupg \\ lsb-release 添加软件源需要的GPG密钥： $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # 如果是国内源： $ curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 配置仓库： $ sudo add-apt-repository \\ \"deb [arch=$(dpkg --print-architecture)https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs)stable\" 或者直接在/etc/apt/sources.list.d/创建一个docker.list文件,添加上式中的引号中的内容， 并修改内容中修改架构和发行版名称。 执行安装： sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io 建立docker用户组： sudo groupadd docker sudo usermod -aG docker $USER 如果一切顺利的话，就安装成功了。 ","date":"2021-11-07","objectID":"/posts/proxy/:2:1","tags":["Docker"],"title":"Docker 安装和网络代理","uri":"/posts/proxy/"},{"categories":["Docker"],"content":"卸载方法 卸载Docker Engine： sudo apt-get purge -y docker-engine docker docker-ce docker-ce-cli containerd.io sudo apt-get autoremove -y --purge docker-engine docker docker-ce docker-ce-cli containerd.io 以上的命令不会删除主机上的镜像、容器、卷和用户创建的配置文件等，如需清理： sudo rm -rf /var/lib/docker /var/lib/containerd /etc/docker sudo rm /etc/apparmor.d/docker sudo groupdel docker sudo rm -rf /var/run/docker.sock ","date":"2021-11-07","objectID":"/posts/proxy/:2:2","tags":["Docker"],"title":"Docker 安装和网络代理","uri":"/posts/proxy/"},{"categories":["Docker"],"content":"3 网络代理配置 在公司经常需要挂代理才可以正常访问互联网。如果是这种情况，需要为Docker配置代理。 在Docker的使用中，需要访问外网的场景一般有： dockerd代理配置 Container代理配置 docker build代理配置 下文主要参考：Docker的三种网络代理配置。 ","date":"2021-11-07","objectID":"/posts/proxy/:3:0","tags":["Docker"],"title":"Docker 安装和网络代理","uri":"/posts/proxy/"},{"categories":["Docker"],"content":"dockerd代理配置 当你执行docker login、docker push、docker pull时，实际上是在和docker-client交互， 这时候docker-client操作dockerd去访问外网的镜像仓库时，就会有相关的API发出，这时候需要给dockerd去配置代理。 docker受到systemd的管控，所以需要修改的是systemd的配置。 sudo mkdir -p /etc/systemd/system/docker.service.d sudo touch /etc/systemd/system/docker.service.d/proxy.conf 这里新创建的配置文件的命名只要符合*.conf的形式即可。添加内容如下： [Service] Environment=\"HTTP_PROXY=http://\u003cproxy-addr\u003e:\u003cproxy-port\u003e\" Environment=\"HTTPS_PROXY=http://\u003cproxy-addr\u003e:\u003cproxy-port\u003e\" Environment=\"NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com\" 其中的代理要换成可用的免密代理。 生效条件 需要重启dockerd才可生效。 重启指令： sudo systemctl daemon-reload sudo systemctl restart docker ","date":"2021-11-07","objectID":"/posts/proxy/:3:1","tags":["Docker"],"title":"Docker 安装和网络代理","uri":"/posts/proxy/"},{"categories":["Docker"],"content":"Container代理配置 配置文件 当容器运行时，容器内的运用需要代理访问时，需要配置~/.docker/config.json，当然只生效在Docker的17.07及其以后版本。 {\"proxies\":{\"default\":{\"httpProxy\": \"http://\u003cproxy-addr\u003e:\u003cproxy-port\u003e\",\"httpsProxy\": \"http://\u003cproxy-addr\u003e:\u003cproxy-port\u003e\",\"noProxy\": \"localhost,127.0.0.1,docker-registry.somecorporation.com\"}}} 以上的配置可以一劳永逸。 环境变量 当然，还有一种是在运行容器时通过环境变量的形式注入，命令是-e或者--env。 注意 注入的代理根据真实需要，如容器是基于ubuntu系统的应该配置http_proxy、https_proxy、no_proxy等。 生效条件 对已经启动的容器无效，对配置后启动的容器立即生效。 ","date":"2021-11-07","objectID":"/posts/proxy/:3:2","tags":["Docker"],"title":"Docker 安装和网络代理","uri":"/posts/proxy/"},{"categories":["Docker"],"content":"docker build代理配置 通过docker build构建镜像，是启动容器并逐层构建。但是上文中的配置文件对其无效。 Dockerfile也可以设置环境变量，有ENV和ARG，这两者的作用一致，但是通过ENV设置的环境变量会一并带到生成的镜像中。 ARG则不会，只在构建的阶段有效。 Dockerfile的ARG和docker build的--build-arg是一致的， 建议在构建时通过--build-arg \u003cvarname\u003e=\u003cvalue\u003e参数来指定或重设置这些变量的值。 所以，docker build配置代理： docker build . \\ --build-arg \"http_proxy=http://\u003cproxy-addr\u003e:\u003cproxy-port\u003e\" \\ --build-arg \"https_proxy=http://\u003cproxy-addr\u003e:\u003cproxy-port\u003e\" \\ --build-arg \"no_proxy=localhost,127.0.0.1,docker-registry.somecorporation.com\" \\ -t your/image:tag 同样，由于是通过环境变量来配置代理，配置生效的环境变量应该要符合实际镜像的要求。 注意 如果代理使用的是localhost:3128这类，必须加上--network host代理才能生效。 或者直接配置代理的外部IP。 生效条件 执行docker build构建镜像时立即生效。 ","date":"2021-11-07","objectID":"/posts/proxy/:3:3","tags":["Docker"],"title":"Docker 安装和网络代理","uri":"/posts/proxy/"},{"categories":null,"content":"时间是最好拍当。 行事： 刻意练习 自我迭代 处世： 辩证 接纳 ","date":"2021-11-06","objectID":"/about/:0:0","tags":null,"title":"向右看齐","uri":"/about/"}]